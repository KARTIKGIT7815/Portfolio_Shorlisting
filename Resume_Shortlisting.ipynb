{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e87869e3-0791-4eb9-b510-1ab0e864c07e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documents successfully added to ChromaDB!\n"
     ]
    }
   ],
   "source": [
    "from PyPDF2 import PdfReader\n",
    "import chromadb\n",
    "\n",
    "# Initialize ChromaDB client\n",
    "client = chromadb.Client()\n",
    "\n",
    "# Create or get the collection\n",
    "collection = client.get_or_create_collection(name=\"resume_collection\")\n",
    "\n",
    "# List of PDF files\n",
    "pdf_files = [\"Kartik_Shingate_Resume.pdf\", \"Alice_Smith_Resume.pdf\", \"Bob_Johnson_Resume.pdf\", \"Charlie_Davis_Resume.pdf\"]\n",
    "\n",
    "# Process each PDF file\n",
    "for pdf_file in pdf_files:\n",
    "    reader = PdfReader(pdf_file)\n",
    "    text = \"\"\n",
    "    \n",
    "    # Extract text from all pages\n",
    "    for page in reader.pages:\n",
    "        text += page.extract_text()\n",
    "    \n",
    "    # Use the file name (without extension) as the ID\n",
    "    person_id = pdf_file.replace(\".pdf\", \"\").replace(\"_\", \" \")\n",
    "    \n",
    "    # Add document and ID to the collection\n",
    "    collection.add(\n",
    "        documents=[text.strip()],\n",
    "        ids=[person_id]\n",
    "    )\n",
    "\n",
    "print(\"Documents successfully added to ChromaDB!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "edfa140a-614c-4cda-bd5b-5a63783b3d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "\n",
    "llm = ChatGroq(\n",
    "    model=\"llama-3.1-70b-versatile\",\n",
    "    temperature=0.5,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    "    api_key='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'\n",
    "    # other params...\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cd457117-d706-4004-b7f5-2d720195b73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_post = '''\n",
    "Swiggy is looking for a talented and results-driven Data Scientist to join our team in Bangalore (with hybrid/remote options available). \n",
    "In this role, you will develop and deploy machine learning models to optimize delivery times, enhance user experiences, and drive operational efficiency.\n",
    "You will analyze large datasets to uncover trends and actionable insights, collaborate with cross-functional teams to design data-driven solutions, \n",
    "and build recommendation systems and predictive analytics models. Weâ€™re seeking candidates with 2-5 years of experience in data science, proficiency in \n",
    "Python, R, or Scala, and familiarity with machine learning frameworks like TensorFlow or Scikit-learn. Hands-on experience with SQL and big data tools\n",
    "(e.g., Hadoop, Spark) is essential, alongside a strong understanding of statistical methods and data visualization techniques.Preferred qualifications \n",
    "include expertise in deep learning, NLP, recommendation systems, and A/B testing, with a bonus for prior experience in e-commerce or logistics domains.\n",
    "Join Swiggy to work on impactful, large-scale projects and help redefine how India eats!\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4953806f-dde0-4cc5-ab01-b32940c33333",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{ \n",
      "\"JOB_ROLE\": \"Data Scientist\", \n",
      "\"EXPERIENCE\": \"2-5 years\", \n",
      "\"SKILLS\": [\"Python\", \"R\", \"Scala\", \"TensorFlow\", \"Scikit-learn\", \"SQL\", \"Hadoop\", \"Spark\", \"Machine Learning\", \"Deep Learning\", \"NLP\", \"Data Visualization\"] \n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You have to extract following details from provided job post. Extract JOB_ROLE, EXPERIENCE, SKILLS in json format  extract only the curly bracket information. Dont provide preamble information\",\n",
    "        ),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt | llm\n",
    "result = chain.invoke(\n",
    "    {\n",
    "        \"input\": job_post,\n",
    "    }\n",
    ")\n",
    "\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7ada0d4e-e7a3-401c-8e94-b8c649556b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "801dd714-ac36-47e5-a3cd-13df09d3a91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Details = json.loads(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e0398caf-d0df-4572-b1ab-60950f5c476d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'JOB_ROLE': 'Data Scientist',\n",
       " 'EXPERIENCE': '2-5 years',\n",
       " 'SKILLS': ['Python',\n",
       "  'R',\n",
       "  'Scala',\n",
       "  'TensorFlow',\n",
       "  'Scikit-learn',\n",
       "  'SQL',\n",
       "  'Hadoop',\n",
       "  'Spark',\n",
       "  'Machine Learning',\n",
       "  'Deep Learning',\n",
       "  'NLP',\n",
       "  'Data Visualization']}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "92a50943-bb05-48f2-8961-642df064d671",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python R Scala TensorFlow Scikit-learn SQL Hadoop Spark Machine Learning Deep Learning NLP Data Visualization 2 - 5   y e a r s\n"
     ]
    }
   ],
   "source": [
    "SE = ' '.join([' '.join(Details['SKILLS']), ' '.join(Details['EXPERIENCE'])])\n",
    "print(SE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "370ba087-01e2-4cb6-b44f-03499656f67b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ids': [['Charlie Davis Resume']], 'embeddings': None, 'documents': [['Resume\\nStudent 3: Charlie Davis\\nContact Information\\nEmail: charlie.davis@example.com\\nPhone: +1 456 789 0123\\nLinkedIn: linkedin.com/in/charliedavis\\nProfessional Summary\\nRecent graduate in Data Science with hands-on experience in machine learning projects and big data technologies.\\nSkills\\nPython, Hadoop, Spark, SQL, Machine Learning, Deep Learning, Data Engineering, Big Data Analytics\\nExperience\\nMachine Learning Intern, JKL Analytics (2023)\\n- Built a machine learning model to predict customer churn with 85% accuracy.\\n- Deployed the model as an API using Flask.\\nResearch Assistant, University Data Lab (2021 - 2022)\\n- Conducted research on natural language processing techniques.\\n- Published findings in a peer-reviewed journal.']], 'uris': None, 'data': None, 'metadatas': [[None]], 'distances': [[1.001784324645996]], 'included': [<IncludeEnum.distances: 'distances'>, <IncludeEnum.documents: 'documents'>, <IncludeEnum.metadatas: 'metadatas'>]}\n"
     ]
    }
   ],
   "source": [
    "results = collection.query(\n",
    "    query_texts=[SE], # Chroma will embed this for you\n",
    "    n_results=1 # how many results to return\n",
    ")\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d06cd892-7e40-44a0-8440-ac9c53669020",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Charlie Davis Resume']]\n"
     ]
    }
   ],
   "source": [
    "names = results.get('ids', [])\n",
    "print(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "95c7e8ac-1f04-490d-a7c0-58e55f768f9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Resume\\nStudent 3: Charlie Davis\\nContact Information\\nEmail: charlie.davis@example.com\\nPhone: +1 456 789 0123\\nLinkedIn: linkedin.com/in/charliedavis\\nProfessional Summary\\nRecent graduate in Data Science with hands-on experience in machine learning projects and big data technologies.\\nSkills\\nPython, Hadoop, Spark, SQL, Machine Learning, Deep Learning, Data Engineering, Big Data Analytics\\nExperience\\nMachine Learning Intern, JKL Analytics (2023)\\n- Built a machine learning model to predict customer churn with 85% accuracy.\\n- Deployed the model as an API using Flask.\\nResearch Assistant, University Data Lab (2021 - 2022)\\n- Conducted research on natural language processing techniques.\\n- Published findings in a peer-reviewed journal.'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "portfolios = ''.join(results['documents'][0])\n",
    "portfolios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8d3dd39f-24cf-478e-8a74-1cf1f94b8c5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: Shortlisted Candidates for TCS Job Post\n",
      "\n",
      "Dear TCS Recruitment Team,\n",
      "\n",
      "We are excited to inform you that we have shortlisted a highly skilled candidate, Charlie Davis, whose portfolio aligns with the requirements of your job post. With a strong background in Data Science and hands-on experience in machine learning projects, Charlie is an ideal fit for your team.\n",
      "\n",
      "Charlie's skills include:\n",
      "\n",
      "* Programming languages: Python\n",
      "* Big Data technologies: Hadoop, Spark\n",
      "* Data Analysis: SQL, Machine Learning, Deep Learning, Data Engineering, Big Data Analytics\n",
      "\n",
      "Some of Charlie's notable experiences include:\n",
      "\n",
      "* Building a machine learning model to predict customer churn with 85% accuracy as a Machine Learning Intern at JKL Analytics\n",
      "* Deploying the model as an API using Flask\n",
      "* Conducting research on natural language processing techniques as a Research Assistant at University Data Lab\n",
      "* Publishing findings in a peer-reviewed journal\n",
      "\n",
      "We believe Charlie would be a valuable asset to your team and would like to schedule an interview at your convenience. Please find Charlie's contact information below:\n",
      "\n",
      "Email: charlie.davis@example.com\n",
      "Phone: +1 456 789 0123\n",
      "LinkedIn: linkedin.com/in/charliedavis\n",
      "\n",
      "We look forward to hearing from you soon.\n",
      "\n",
      "Best regards,\n",
      "[Your Name]\n",
      "Placement Officer, Codespyder Consultancy\n"
     ]
    }
   ],
   "source": [
    "#from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "email_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            '''We are working as a placement officer in placement consultancy codespyder.\n",
    "            We have short listed candidates portfolio as per the requrement of TCS job post.\n",
    "            Create an email to recruitment team of TCS mentioning that we have best suitable candidates for your job post.\n",
    "            Do not provide preamble''',\n",
    "        ),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "email_chain = email_prompt | llm\n",
    "result = email_chain.invoke(\n",
    "    {\n",
    "        \"input\": portfolios,\n",
    "    }\n",
    ")\n",
    "\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39faf78d-b78e-4a6d-a8ee-25eff4f19822",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6fb8bf-0365-4fc3-96cf-5ae3886b8426",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9994ed3f-132b-4768-a064-add5e4aec45e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
